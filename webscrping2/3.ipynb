{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the\n",
    "webpage as shown below:\n",
    "    You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name,\n",
    "experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done\n",
    "manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary modules\n",
    "import pandas as pd\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver import chrome\n",
    "from selenium.common.exceptions import *\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "def job3(url):\n",
    "\n",
    "    #Every time before scraping we have to check the responce from website if it is 200 we can scrap any data\n",
    "    request = requests.get(url)\n",
    "    print(\"The reponse is :\", request)\n",
    "\n",
    "    #lets get the the chrome driver file stored in system so that we can acess the browser\n",
    "\n",
    "    driver = webdriver.Chrome('/home/santosh/Downloads/chromedriver_linux64/chromedriver')\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    #now we have to search the job description and location to search the data\n",
    "    #there are two search boxes at the starting page\n",
    "    jobdescription = driver.find_element_by_id(\"qsb-keyword-sugg\").send_keys(\"Data Scientist\")\n",
    "\n",
    "    #here i am searching for jobsin bangalore location\n",
    "    #and at last i am going to click on search button\n",
    "\n",
    "    button = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "    button.click()\n",
    "    driver.maximize_window()\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    #now we have to click the checkboxes as per the problem statement the location filter is \"Delhi\" and salary is 3-6 lakh\n",
    "    #this is checkbox of location\n",
    "\n",
    "\n",
    "    try:\n",
    "        filter1 = driver.find_element_by_xpath(\"//span[@class='ellipsis fleft'][contains(text(),'Delhi / NCR')]\").click()\n",
    "    except ElementNotInteractableException:\n",
    "        print(\"not accesable\")\n",
    "\n",
    "\n",
    "    #now lets create another filter for salary\n",
    "\n",
    "\n",
    "    try:\n",
    "        filter2 = driver.find_element_by_xpath(\"//span[contains(text(),'3-6 Lakhs')]\").click()\n",
    "    except ElementNotInteractableException:\n",
    "        print(\"mot accessable\")\n",
    "\n",
    "\n",
    "    #actually .click() method used to click on the data, and we are done with filtering now lets start scraping results\n",
    "    #creating lists for storin data\n",
    "\n",
    "    job_title = []\n",
    "    job_location  = []\n",
    "    company_name = []\n",
    "    experience_list = []\n",
    "\n",
    "    #here lets start with the titles block here i am using xpath to find webelemunts to fetch job titles pf that page\n",
    "    #as we can see i have using slicling methd in the for loop to fetch only 10 values \n",
    "    # i have used exception handling so that we can execute the code easily with out any errors or exceptions\n",
    "    try:\n",
    "        titles = driver.find_elements_by_xpath(\"//a[@class = 'title fw500 ellipsis']\")\n",
    "        for title in titles[:10]:\n",
    "            job_title.append(title.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    # this is the blockfor comapny details, here  also i have used xpath for fetching\n",
    "\n",
    "    try:\n",
    "        company = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "        for com in company[:10]:\n",
    "            company_name.append(com.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    #this is the block for location data\n",
    "\n",
    "    try:\n",
    "        location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "        for loc in location[:10]:\n",
    "            job_location.append(loc.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    #this is the block for experience data \n",
    "\n",
    "    try:\n",
    "        experience = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "        for exp in experience[:10]:\n",
    "            experience_list.append(exp.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "    #we have got all the required data lets create a datafrme so thet we can save the file in csv or json format\n",
    "\n",
    "    naukari_jobs3 = pd.DataFrame({})\n",
    "    \n",
    "    naukari_jobs3[\"Title\"] = job_title\n",
    "        \n",
    "    naukari_jobs3[\"Company\"] = company_name\n",
    "        \n",
    "    naukari_jobs3[\"Location\"] = job_location\n",
    "        \n",
    "    naukari_jobs3[\"Experience\"] = experience_list\n",
    "        \n",
    "    return naukari_jobs3\n",
    "\n",
    "#calling the function\n",
    "job3(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbasecondaf5ae4ab580394e4693ea5507f08b0bfd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
